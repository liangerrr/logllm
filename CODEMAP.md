# LogLLM é¡¹ç›®ä»£ç åœ°å›¾

> **æœ€åæ›´æ–°**: 2025-12-04  
> **é¡¹ç›®ç»“æ„**: ä»£ç ã€æ•°æ®ã€è„šæœ¬åˆ†ç¦»

## ğŸ“ ç›®å½•ç»“æ„

```
LogLLM/
â”œâ”€â”€ data/                          # æ•°æ®ç›®å½•ï¼ˆæœ¬åœ°ç”Ÿæˆçš„æ•°æ®ï¼‰
â”‚   â””â”€â”€ HDFS_data/                 # HDFS æ•°æ®é›†è½¬æ¢åçš„æ–‡ä»¶
â”‚       â”œâ”€â”€ HDFS.log              # åŸå§‹æ—¥å¿—æ–‡ä»¶
â”‚       â””â”€â”€ anomaly_label.csv     # BlockId å’Œ Label æ˜ å°„
â”‚
â”œâ”€â”€ scripts/                       # å·¥å…·è„šæœ¬ç›®å½•
â”‚   â”œâ”€â”€ download_hdfs.py          # ä¸‹è½½ HDFS æ•°æ®é›†
â”‚   â”œâ”€â”€ convert_hdfs.py            # è½¬æ¢æ•°æ®é›†æ ¼å¼
â”‚   â””â”€â”€ test_huggingface.py       # æµ‹è¯• HuggingFace è¿æ¥
â”‚
â”œâ”€â”€ prepareData/                   # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”‚   â”œâ”€â”€ helper.py                 # è¾…åŠ©å‡½æ•°ï¼ˆçª—å£ã€æ—¥å¿—è§£æç­‰ï¼‰
â”‚   â”œâ”€â”€ sliding_window.py         # æ»‘åŠ¨çª—å£ï¼ˆBGL/Thunderbird/Libertyï¼‰
â”‚   â””â”€â”€ session_window.py         # ä¼šè¯çª—å£ï¼ˆHDFSï¼‰
â”‚
â”œâ”€â”€ ft_model_*/                   # å¾®è°ƒåçš„æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ Bert_ft/                  # BERT LoRA é€‚é…å™¨
â”‚   â”œâ”€â”€ Llama_ft/                 # Llama LoRA é€‚é…å™¨
â”‚   â””â”€â”€ projector.pt              # æŠ•å½±å±‚æƒé‡
â”‚
â”œâ”€â”€ model.py                       # LogLLM æ¨¡å‹å®šä¹‰
â”œâ”€â”€ customDataset.py               # è‡ªå®šä¹‰æ•°æ®é›†å’Œé‡‡æ ·å™¨
â”œâ”€â”€ train.py                       # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ eval.py                        # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ test_model.py                  # æ¨¡å‹æµ‹è¯•è„šæœ¬
â”œâ”€â”€ requirements.txt               # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                      # é¡¹ç›®è¯´æ˜
```

---

## ğŸ”„ æ•°æ®æµç¨‹

### 1. æ•°æ®ä¸‹è½½å’Œè½¬æ¢ï¼ˆæœ¬åœ°ï¼‰

```bash
# æ­¥éª¤ 1: ä¸‹è½½æ•°æ®é›†
cd scripts
python download_hdfs.py
# è¾“å‡º: /Users/lc/PycharmProjects/HDFS_v1 (HuggingFace æ ¼å¼)

# æ­¥éª¤ 2: è½¬æ¢æ ¼å¼
python convert_hdfs.py
# è¾“å‡º: data/HDFS_data/HDFS.log å’Œ anomaly_label.csv
```

### 2. æ•°æ®é¢„å¤„ç†ï¼ˆæœåŠ¡å™¨ï¼‰

```bash
# ä¸Šä¼  data/HDFS_data/ åˆ°æœåŠ¡å™¨ /mnt/public/gw/SyslogData/HDFS_v1/

# åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œé¢„å¤„ç†
python prepareData/session_window.py
# è¾“å‡º: train.csv å’Œ test.csv
```

### 3. è®­ç»ƒå’Œè¯„ä¼°ï¼ˆæœåŠ¡å™¨ï¼‰

```bash
# è®­ç»ƒ
python train.py

# è¯„ä¼°
python eval.py
```

---

## ğŸ“ æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

### `model.py` - LogLLM æ¨¡å‹

- **LogLLM ç±»**: ä¸»æ¨¡å‹ç±»
  - `Bert_path`: BERT æ¨¡å‹è·¯å¾„
  - `Llama_path`: Llama æ¨¡å‹è·¯å¾„
  - `ft_path`: å¾®è°ƒæƒé‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
- **å…³é”®æ–¹æ³•**:
  - `train_helper()`: è®­ç»ƒæ—¶çš„å‰å‘ä¼ æ’­
  - `forward()`: æ¨ç†æ—¶çš„å‰å‘ä¼ æ’­
  - `save_ft_model()`: ä¿å­˜å¾®è°ƒæƒé‡

### `customDataset.py` - æ•°æ®é›†å¤„ç†

- **CustomDataset**: ä» CSV è¯»å–æ—¥å¿—åºåˆ—
- **CustomCollator**: æ‰¹å¤„ç†å’Œæ•°æ®æ‰“åŒ…
- **BalancedSampler**: å¹³è¡¡é‡‡æ ·å™¨ï¼ˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰

### `train.py` - è®­ç»ƒæµç¨‹

**å¤šé˜¶æ®µè®­ç»ƒ**:
1. **Phase 1**: åªè®­ç»ƒ Llama (`set_train_only_Llama`)
2. **Phase 2-1**: åªè®­ç»ƒ projector (`set_train_only_projector`)
3. **Phase 2-2**: è®­ç»ƒ projector + Bert (`set_train_projectorAndBert`)
4. **Phase 3**: ç«¯åˆ°ç«¯å¾®è°ƒ (`set_finetuning_all`)

### `eval.py` - è¯„ä¼°æµç¨‹

- åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
- åœ¨æµ‹è¯•é›†ä¸Šæ¨ç†
- è®¡ç®— precision, recall, F1, accuracy

### `prepareData/` - æ•°æ®é¢„å¤„ç†

- **sliding_window.py**: BGL/Thunderbird/Liberty æ•°æ®é›†
  - ä½¿ç”¨å›ºå®šå¤§å°çª—å£åˆ†ç»„æ—¥å¿—
  - ç”Ÿæˆ `train.csv` å’Œ `test.csv`
- **session_window.py**: HDFS æ•°æ®é›†
  - æŒ‰ BlockId åˆ†ç»„æ—¥å¿—
  - éœ€è¦ `anomaly_label.csv` æ–‡ä»¶

---

## ğŸ—‚ï¸ æ•°æ®è·¯å¾„é…ç½®

### æœ¬åœ°ï¼ˆMacï¼‰

- **HuggingFace æ•°æ®é›†**: `/Users/lc/PycharmProjects/HDFS_v1`
- **è½¬æ¢åçš„æ•°æ®**: `data/HDFS_data/`
  - `HDFS.log`
  - `anomaly_label.csv`

### æœåŠ¡å™¨ï¼ˆLinuxï¼‰

- **æ¨¡å‹è·¯å¾„**:
  - Llama: `/hy-tmp/model_weights/LLM-Research/Meta-Llama-3-8B`
  - BERT: `/hy-tmp/model_weights/AI-ModelScope/bert-base-uncased`
- **æ•°æ®è·¯å¾„**: `/mnt/public/gw/SyslogData/{dataset_name}/`
  - `train.csv`
  - `test.csv`

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æœ¬åœ°ç¯å¢ƒï¼ˆæ•°æ®è½¬æ¢ï¼‰

```bash
# 1. å®‰è£…ä¾èµ–
pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple datasets pandas pyarrow tqdm

# 2. è®¾ç½® HuggingFace token
export HF_TOKEN=your_token

# 3. ä¸‹è½½å’Œè½¬æ¢æ•°æ®
cd scripts
python download_hdfs.py
python convert_hdfs.py
```

### æœåŠ¡å™¨ç¯å¢ƒï¼ˆè®­ç»ƒ/è¯„ä¼°ï¼‰

```bash
# 1. æ¿€æ´»ç¯å¢ƒ
conda activate logllm

# 2. ä¸Šä¼ æ•°æ®åˆ°æœåŠ¡å™¨

# 3. è¿è¡Œé¢„å¤„ç†
python prepareData/session_window.py

# 4. è®­ç»ƒæˆ–è¯„ä¼°
python train.py
python eval.py
```

---

## ğŸ“Š æ•°æ®é›†æ”¯æŒ

| æ•°æ®é›† | é¢„å¤„ç†è„šæœ¬ | å¾®è°ƒæ¨¡å‹ | LogLLM F1 |
|:------|:---------|:--------|:---------|
| **HDFS** | `session_window.py` | `ft_model_HDFS/` | 0.997 |
| **BGL** | `sliding_window.py` | `ft_model_BGL/` | 0.916 |
| **Liberty** | `sliding_window.py` | `ft_model_Liberty/` | 0.958 |
| **Thunderbird** | `sliding_window.py` | `ft_model_Thunderbird/` | 0.966 |

---

## ğŸ”§ è„šæœ¬è¯´æ˜

### `scripts/download_hdfs.py`

ä» HuggingFace ä¸‹è½½ HDFS_v1 æ•°æ®é›†ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
python scripts/download_hdfs.py
```

**è¾“å‡º**: `/Users/lc/PycharmProjects/HDFS_v1` (HuggingFace datasets æ ¼å¼)

### `scripts/convert_hdfs.py`

å°† HuggingFace datasets æ ¼å¼è½¬æ¢ä¸ºä»£ç éœ€è¦çš„æ ¼å¼ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
python scripts/convert_hdfs.py
```

**è¾“å…¥**: `/Users/lc/PycharmProjects/HDFS_v1`  
**è¾“å‡º**: `data/HDFS_data/HDFS.log` å’Œ `anomaly_label.csv`

### `scripts/test_huggingface.py`

æµ‹è¯• HuggingFace è¿æ¥å’Œè®¤è¯çŠ¶æ€ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
python scripts/test_huggingface.py
```

---

## âš™ï¸ é…ç½®è¦ç‚¹

### è®­ç»ƒé…ç½® (`train.py`)

```python
dataset_name = 'HDFS_v1'  # æˆ– 'BGL', 'Liberty', 'Thunderbird'
Bert_path = "/hy-tmp/model_weights/AI-ModelScope/bert-base-uncased"
Llama_path = "/hy-tmp/model_weights/LLM-Research/Meta-Llama-3-8B"
data_path = f'/mnt/public/gw/SyslogData/{dataset_name}/train.csv'
```

### è¯„ä¼°é…ç½® (`eval.py`)

```python
dataset_name = 'HDFS_v1'
data_path = f'/mnt/public/gw/SyslogData/{dataset_name}/test.csv'
ft_path = f"ft_model_{dataset_name}"  # è‡ªåŠ¨åŠ è½½å¯¹åº”å¾®è°ƒæ¨¡å‹
```

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

1. **æœ¬åœ°å’ŒæœåŠ¡å™¨ç¯å¢ƒåˆ†ç¦»**:
   - æœ¬åœ°ï¼šåªå®‰è£…æ•°æ®å¤„ç†ä¾èµ–ï¼ˆdatasets, pandas, pyarrow, tqdmï¼‰
   - æœåŠ¡å™¨ï¼šå®‰è£…å®Œæ•´ä¾èµ–ï¼ˆPyTorch, transformers, peft ç­‰ï¼‰

2. **æ•°æ®è·¯å¾„**:
   - æœ¬åœ°ç”Ÿæˆçš„æ•°æ®åœ¨ `data/` ç›®å½•
   - éœ€è¦ä¸Šä¼ åˆ°æœåŠ¡å™¨çš„ `/mnt/public/gw/SyslogData/` ç›®å½•

3. **æ¨¡å‹è·¯å¾„**:
   - æœåŠ¡å™¨ä¸Šçš„æ¨¡å‹è·¯å¾„æ˜¯å›ºå®šçš„ï¼ˆè§ README_SERVER.mdï¼‰
   - æœ¬åœ°ä¸éœ€è¦æ¨¡å‹æ–‡ä»¶

4. **HuggingFace Token**:
   - ä¸‹è½½æ•°æ®é›†éœ€è¦ token
   - åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® `HF_TOKEN`

---

**Happy Coding! ğŸš€**

